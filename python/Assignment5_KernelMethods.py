# -*- coding: utf-8 -*-
"""Bagaipo_Assignment5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xXKtb07xksZdsUsiphygKfgm_5rIeCV1

A support vector machine (SVM) is a type of algorithm that can be used for classification and regression tasks. It works by finding the best hyperplane that can linearly separate the data into different classes. This hyperplane is called the "decision boundary," and it is used to make predictions on new data.

SVMs are particularly useful when working with high-dimensional datasets, as they can help to find the most important features that can be used to make accurate predictions.

In summary, an SVM is a powerful algorithm that can be used for classification and regression tasks, and it is particularly well-suited to high-dimensional datasets.
"""

# Import necessary libraries
import numpy as np
import pandas as pd
import seaborn as sns

# Load the iris dataset
url = 'https://raw.githubusercontent.com/fabagaipo/cmsc173ml/main/datasets/IRIS.csv'
data = pd.read_csv(url)
data.head()

# Split the dataset into features and labels
X = data.drop('species', axis=1)
y = data['species']

# Split dataset into training set and test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=888)

# Import svm model
from sklearn import svm
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

"""Basically the gist of a SVM is that it needs to:

Choose a kernel function: An SVM uses a kernel function to project the data into a higher-dimensional space, where it is easier to find the decision boundary. Choose a kernel function, such as a linear, polynomial, or radial basis function (RBF) kernel.

Find the support vectors: The support vectors are the points in the training set that are closest to the decision boundary. These points are the most important for defining the boundary, and they are used to make predictions on new data.

Find the decision boundary: Use the support vectors and the chosen kernel function to find the decision boundary that best separates the data into different classes.

"""

# Define the SVM model
model = svm.SVC(kernel='linear', C=1.0, gamma=1.0)

"""If we did the algorithm form scratch then the steps in how a SVM works are usually:
- Initialize the SVM classifier with the desired parameters, such as the kernel type and regularization constant.
- Implement the training algorithm for the SVM classifier. This typically involves finding the hyperplane that maximally separates the two classes in the dataset, using techniques such as gradient descent or the dual problem.
- Implement the prediction algorithm for the SVM classifier. This involves using the trained model to calculate the distances of new data points to the hyperplane and determining which class they belong to based on the sign of the distance.

Mathematically, this is accomplished by defining the decision boundary as the set of points that are equidistant from the two classes. This can be represented as a hyperplane in N-dimensional space, where N is the number of features in the dataset. The equation for this hyperplane is typically represented as:

$ w_1 * x_1 + w_2 * x_2 + ... + w_n * x_n + b = 0 $

where `w` is a vector of coefficients and `b` is the bias term. The coefficients and bias term are learned from the training data using an optimization algorithm, such as gradient descent.

Once the hyperplane is found, new data points can be classified by computing their distance from the hyperplane and assigning them to the appropriate class based on this distance. For example, if a new data point is on the positive side of the hyperplane (relative to the orientation of the normal vector), it would be classified as belonging to one class, and if it is on the negative side, it would be classified as belonging to the other class.
"""

# Train the model on the training data
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

"""Once the model is trained, it can be used to make predictions on unseen data. In this case, the code uses the trained model to make predictions on the same Iris dataset that was used for training."""

# Evaluate the model on the test data
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

report = classification_report(y_test, y_pred)
print(report)

cm = confusion_matrix(y_test, model.predict(X_test))
sns.heatmap(cm, annot=True, fmt=".0f")

"""Overall, the code creates an SVM model using the Iris dataset, trains the model on the dataset, makes predictions using the trained model, and evaluates the model's performance."""