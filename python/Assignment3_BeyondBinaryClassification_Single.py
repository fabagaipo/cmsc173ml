# -*- coding: utf-8 -*-
"""Bagaipo_Assignment3_Abalone.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JIZ4y-iVPqsr6iKKk_KNTXvGHideyLpn

# Imports
"""

import pandas as pd
import seaborn as sns

"""# Reading the Dataset"""

url = 'https://raw.githubusercontent.com/fabagaipo/cmsc173ml/main/datasets/abalone19.dat'
df = pd.read_csv(url)
df.head()

df.shape

df.info()

df.corr()

sns.heatmap(df.corr())

"""# Cleaning the Dataset"""

df.isnull().sum()

len(df[df.duplicated()])

df['Class'].value_counts()

sns.countplot(df['Class'])

df['Class'] = df['Class'].map(lambda x: 0 if x == 'negative' else 1)
df = pd.get_dummies(df, columns=['Sex'], drop_first=True)
df

"""# Splitting data"""

X = df.drop(["Class"], axis=1)
y = df.Class
test_size = 0.2     # 80% training and 20% testing

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=888)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

"""# Model Evaluation with Imbalanced Dataset"""

# from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

# model = LogisticRegression(multi_class='ovr', solver='liblinear')
model = KNeighborsClassifier()

y_train.value_counts()

model.fit(X_train, y_train)
y_pred = model.predict(X_test)

accuracy_original = accuracy_score(y_test, y_pred)
print("Accuracy: %.3f%%" % (accuracy_original))

report_original = classification_report(y_test, y_pred)
print(report_original)

confusionMatrix_original = confusion_matrix(y_test, model.predict(X_test))
sns.heatmap(confusionMatrix_original, annot=True, fmt=".0f")

"""# Handling Imbalanced Dataset"""

pip install -U imbalanced-learn

"""---
- Undersampling Method
"""

from imblearn.under_sampling import RandomUnderSampler
rus = RandomUnderSampler()
X_resampled_under, y_resampled_under = rus.fit_resample(X_train, y_train)

y_resampled_under.value_counts()

model.fit(X_resampled_under, y_resampled_under)
y_pred_under = model.predict(X_test)

accuracy_under = accuracy_score(y_test, y_pred_under)
print("Accuracy: %.3f%%" % (accuracy_under))

report_under = classification_report(y_test, y_pred_under)
print(report_under)

confusionMatrix_under = confusion_matrix(y_test, model.predict(X_test))
sns.heatmap(confusionMatrix_under, annot=True, fmt=".0f")

"""---
- Oversampling Method
"""

from imblearn.over_sampling import RandomOverSampler
ros = RandomOverSampler()
X_resampled_over, y_resampled_over = ros.fit_resample(X_train, y_train)

y_resampled_over.value_counts()

model.fit(X_resampled_over, y_resampled_over)
y_pred_over = model.predict(X_test)

accuracy_over = accuracy_score(y_test, y_pred_over)
print("Accuracy: %.3f%%" % (accuracy_over))

report_over = classification_report(y_test, y_pred_over)
print(report_over)

confusionMatrix_over = confusion_matrix(y_test, model.predict(X_test))
sns.heatmap(confusionMatrix_over, annot=True, fmt=".0f")

"""# Evaluation

Doing model evaluation with the imbalanced dataset, we can see the accuracy at 99% making the result be unreliable and misleading, leading it to have an accuracy pitfall. Does this mean our model is running correctly? No, it just shows how uneven our dataset really is. This is the definition of imbalanced datasets. Imbalanced datasets are those where there is a severe skew in the class distribution, such as 1:100 or 1:1000 examples in the minority class to the majority class. As can be seen in the report for the original dataset, the metrics of class = 1 are low. Although our model has a high accuracy, the accuracy only reflects that of class = 0. The model on the original dataset can predict with 0.60 accuracies, but when we look at the Confusion Matrix, the rate of false predictions in class=0 is quite high. Actually, the model correctly predicts the negative class with 0.99 accuracies. Because our dataset is an imbalanced dataset

After handling our imbalanced dataset with the methods of oversampling and undersampling, we see the accuracy drop down from the results of the original dataset (undersampling = 63% and oversampling = 80%). This is a significance decrease from that of the original report. According to the model, the prediction of the negative abalone class (class = 0) has decreased, but there is also an increase in the recall metric of class = 1 or the positive abalone class, which means that the rate of predicting class = 1 of the model increased.
"""